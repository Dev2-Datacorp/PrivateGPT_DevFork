{"docstore/data": {"1305a915-b97f-432a-923a-a192add7ebe0": {"__data__": {"id_": "1305a915-b97f-432a-923a-a192add7ebe0", "embedding": null, "metadata": {"page_label": "1", "file_name": "understaing-support-vector-machine-example-code.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9b2ad5f8-ab26-4090-beb1-7a5a3d6a42d2", "node_type": null, "metadata": {"page_label": "1", "file_name": "understaing-support-vector-machine-example-code.pdf"}, "hash": "4ea16c65a00d52976b68fa9789a367f51d7f21e36fd6befb49e3c539b4a95107"}, "3": {"node_id": "d7520b64-4628-4d44-9cd5-46e1d8d81a64", "node_type": null, "metadata": {"page_label": "1", "file_name": "understaing-support-vector-machine-example-code.pdf"}, "hash": "1e27def494d9833a3cf428648305b4e91c532b0272c032e63034b202a5175e8f"}}, "hash": "57ece9fbdebcda7b56e1fe9c2c7fe57038f5b4c97228f3692fe207541382a2b4", "text": "Understanding Support Vector Machine(SVM) algorithm from\nexamples (along with code)\nNote: This article was originally published on Oct 6th, 2015 and updated on Sept 13th, 2017\nOverview\nExplanation of support vector machine (SVM), a popular machine learning algorithm or classification\nImplementation of SVM in R and Python\nLearn about the pros and cons of Support Vector Machines(SVM) and its different applications\n\u00a0\nIntroduction\nMastering machine learning algorithms isn\u2019t a myth at all. Most of the beginners start by learning\nregression. It is simple to learn and use, but does that solve our purpose? Of course not! Because you can\ndo so much more than just Regression!\nThink of machine learning algorithms as an armoury packed with axes, sword, blades, bow, dagger, etc. You\nhave various tools, but you ought to learn to use them at the right time. As an analogy, think of \u2018Regression\u2019\nas a sword capable of slicing and dicing data efficiently, but incapable of dealing with highly complex data.\nOn the contrary, \u2018Support Vector Machines\u2019 is like a sharp knife \u2013 it works on smaller datasets, but on the\ncomplex ones, it can be much stronger and powerful in building machine learning models.\nBy now, I hope you\u2019ve now mastered Random Forest,\u00a0Naive Bayes Algorithm\u00a0and Ensemble Modeling. If not,\nI\u2019d suggest you take out a few minutes and read about them as well. In this article, I shall guide you\nthrough the basics to advanced knowledge of a crucial machine learning algorithm, support vector\nmachines.\nYou can learn about Support Vector Machines in course format here (it\u2019s free!):\nSupport Vector Machines (SVM) in Python and R\nIf you\u2019re a beginner looking to start your data science journey, you\u2019ve come to the right place! Check out the\nbelow comprehensive courses, curated by industry experts, that we have created just for", "start_char_idx": 0, "end_char_idx": 1835, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d7520b64-4628-4d44-9cd5-46e1d8d81a64": {"__data__": {"id_": "d7520b64-4628-4d44-9cd5-46e1d8d81a64", "embedding": null, "metadata": {"page_label": "1", "file_name": "understaing-support-vector-machine-example-code.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9b2ad5f8-ab26-4090-beb1-7a5a3d6a42d2", "node_type": null, "metadata": {"page_label": "1", "file_name": "understaing-support-vector-machine-example-code.pdf"}, "hash": "4ea16c65a00d52976b68fa9789a367f51d7f21e36fd6befb49e3c539b4a95107"}, "2": {"node_id": "1305a915-b97f-432a-923a-a192add7ebe0", "node_type": null, "metadata": {"page_label": "1", "file_name": "understaing-support-vector-machine-example-code.pdf"}, "hash": "57ece9fbdebcda7b56e1fe9c2c7fe57038f5b4c97228f3692fe207541382a2b4"}}, "hash": "1e27def494d9833a3cf428648305b4e91c532b0272c032e63034b202a5175e8f", "text": "courses, curated by industry experts, that we have created just for you:\nIntroduction to Data Science\nCertified Program: Data Science for Beginners (with Interviews)\nALGORITHM\nCLASSIFICATION\nDATA SCIENCE\nINTERMEDIATE\nMACHINE LEARNING\nPYTHON\nR\nSTRUCTURED DATA\nSUPERVISED", "start_char_idx": 1768, "end_char_idx": 2037, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "3b36b885-cb52-464a-bf34-05771835590b": {"__data__": {"id_": "3b36b885-cb52-464a-bf34-05771835590b", "embedding": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "dbd66dbf-3521-460c-99da-2efb40e9ce56", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "f16cd5eb95a0ce8c0945c98f03ec3fd1df715ac871611f1c14d68322d2863fdc"}, "3": {"node_id": "2da087bc-0e21-4e03-a6ea-8cc88d49dbd5", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "4a4247d908dec4d07776a78c4fece09ece6787f60a9a97fe843f71884eb6284b"}}, "hash": "27ff12ae60c00cc65c484ea528ba69ca019660a797f2e5952e25802d7c9370e0", "text": "Data Science Cheatsheet 2.0\nLast Updated June 19, 2021\nDistributions\nDiscrete\nBinomial -xsuccesses in nevents, each with pprobability\n!\u0000n\nx\u0001\npxqn\u0000x, with\u0016=npand\u001b2=npq\n{ If n = 1, this is a Bernoulli distribution\nGeometric - \frst success with pprobability on the nthtrial\n!qn\u00001p, with\u0016= 1=pand\u001b2=1\u0000p\np2\nNegative Binomial - number of failures before rsuccesses\nHypergeometric -xsuccesses in ndraws, no replacement,\nfrom a size Npopulation with Xitems of that feature\n!\u0010X\nx\u0011\u0010N\u0000X\nn\u0000x\u0011\n\u0010N\nn\u0011 , with\u0016=nX\nN\nPoisson - number of successes xin a \fxed time interval, where\nsuccess occurs at an average rate \u0015!\u0015xe\u0000\u0015\nx!, with\u0016=\u001b2=\u0015\nContinuous\nUniform - all values between aandbare equally likely\n!1\nb\u0000awith\u0016=a+b\n2and\u001b2=(b\u0000a)2\n12orn2\u00001\n12if discrete\nNormal/Gaussian N(\u0016;\u001b), Standard Normal Z\u0018N(0;1)\n{ Central Limit Theorem - sample mean of i.i.d. data\napproaches normal distribution\n{ Empirical Rule - 68%, 95%, and 99.7% of values lie within\none, two, and three standard deviations of the mean\n{ Normal Approximation - discrete distributions such as\nBinomial and Poisson can be approximated using z-scores\nwhennp,nq, and\u0015are greater than 10\nExponential - memoryless time between independent events\noccurring at an average rate \u0015!\u0015e\u0000\u0015x, with\u0016=1\n\u0015Gamma - time until nindependent events occurring at an\naverage rate \u0015\nConcepts\nPrediction Error = Bias2+ Variance + Irreducible Noise\nBias - wrong assumptions when training", "start_char_idx": 0, "end_char_idx": 1404, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "2da087bc-0e21-4e03-a6ea-8cc88d49dbd5": {"__data__": {"id_": "2da087bc-0e21-4e03-a6ea-8cc88d49dbd5", "embedding": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "dbd66dbf-3521-460c-99da-2efb40e9ce56", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "f16cd5eb95a0ce8c0945c98f03ec3fd1df715ac871611f1c14d68322d2863fdc"}, "2": {"node_id": "3b36b885-cb52-464a-bf34-05771835590b", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "27ff12ae60c00cc65c484ea528ba69ca019660a797f2e5952e25802d7c9370e0"}, "3": {"node_id": "a340ca99-39a6-49c9-b799-60c944599307", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "7bd661a8d4d12606c6e9a93da780ecc48130afa142c70b4200021a72e1a1e3d9"}}, "hash": "4a4247d908dec4d07776a78c4fece09ece6787f60a9a97fe843f71884eb6284b", "text": "Variance + Irreducible Noise\nBias - wrong assumptions when training !can't capture\nunderlying patterns !under\ft\nVariance - sensitive to \ructuations when training !can't\ngeneralize on unseen data !over\ft\nThe bias-variance tradeo\u000b attempts to minimize these two\nsources of error, through methods such as:\n{ Cross validation to generalize to unseen data\n{ Dimension reduction and feature selection\nIn all cases, as variance decreases, bias increases.\nML models can be divided into two types:\n{ Parametric - uses a \fxed number of parameters with\nrespect to sample size\n{ Non-Parametric - uses a \rexible number of parameters and\ndoesn't make particular assumptions on the data\nCross Validation - validates test error with a subset of\ntraining data, and selects parameters to maximize average\nperformance\n{k-fold - divide data into kgroups, and use one to validate\n{ leave-p-out - usepsamples to validate and the rest to trainModel Evaluation\nRegression\nMean Squared Error (MSE) =1\nnP(yi\u0000^y)2\nSum of Squared Error (SSE) =P(yi\u0000^y)2\nTotal Sum of Squares (SST) =P(yi\u0000\u0016y)2\nR2= 1\u0000SSE\nSST, the proportion of explained y-variability\nNote, negative R2means the model is worse than just\npredicting the mean. R2is not valid for nonlinear models, as\nSSresidual+SSerror6=SST.\nAdjusted R2= 1\u0000(1\u0000R2)N\u00001\nN\u0000p\u00001, which changes only when\npredictors a\u000bect R2above what would be expected by chance\nClassi\fcation\nPredict Yes Predict No\nActual Yes True Positive (1\u0000\f) False Negative ( \f)\nActual No False Positive ( \u000b) True Negative (1 \u0000\u000b)\n{ Precision =TP\nTP+FP,", "start_char_idx": 1346, "end_char_idx": 2879, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a340ca99-39a6-49c9-b799-60c944599307": {"__data__": {"id_": "a340ca99-39a6-49c9-b799-60c944599307", "embedding": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "dbd66dbf-3521-460c-99da-2efb40e9ce56", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "f16cd5eb95a0ce8c0945c98f03ec3fd1df715ac871611f1c14d68322d2863fdc"}, "2": {"node_id": "2da087bc-0e21-4e03-a6ea-8cc88d49dbd5", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "4a4247d908dec4d07776a78c4fece09ece6787f60a9a97fe843f71884eb6284b"}, "3": {"node_id": "f42a8b9f-4ea6-4594-851e-01282172eabd", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "28c4876593252db78883d165f4dd5282001e2100fdea8c8e9f345c45e496f576"}}, "hash": "7bd661a8d4d12606c6e9a93da780ecc48130afa142c70b4200021a72e1a1e3d9", "text": "True Negative (1 \u0000\u000b)\n{ Precision =TP\nTP+FP, percent correct when predict positive\n{ Recall, Sensitivity =TP\nTP+FN, percent of actual positives\nidenti\fed correctly (True Positive Rate)\n{ Speci\fcity =TN\nTN+FP, percent of actual negatives identi\fed\ncorrectly, also 1 - FPR (True Negative Rate)\n{F1= 2precision\u0001recall\nprecision +recall, useful when classes are imbalanced\nROC Curve - plots TPR vs. FPR for every threshold \u000b. Area\nUnder the Curve measures how likely the model di\u000berentiates\npositives and negatives (perfect AUC = 1, baseline = 0.5).\nPrecision-Recall Curve - focuses on the correct prediction\nof the minority class, useful when data is imbalanced\nLinear Regression\nModels linear relationships between a continuous response and\nexplanatory variables\nOrdinary Least Squares - \fnd ^\ffor ^y=^\f0+^\fX+\u000fby\nsolving ^\f= (XTX)\u00001XTYwhich minimizes the SSE\nAssumptions\n{ Linear relationship and independent observations\n{ Homoscedasticity - error terms have constant variance\n{ Errors are uncorrelated and normally distributed\n{ Low multicollinearity\nVariance In\ration Factor - measures the severity of\nmulticollinearity!1\n1\u0000Ri2, whereRi2is found by regressing\nXiagainst all other variables (a common VIF cuto\u000b is 10)\nRegularization\nAdd a penalty \u0015for large coe\u000ecients to the cost function,\nwhich reduces over\ftting. Requires normalized data.\nSubset (L0):\u0015jj^\fjj0=\u0015(numberof non\u0000zerovariables )\n{ Computationally slow, need to \ft 2kmodels\n{ Alternatives: forward and backward stepwise selection\nLASSO (L1):\u0015jj^\fjj1=\u0015Pj^\fj\n{", "start_char_idx": 2901, "end_char_idx": 4423, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f42a8b9f-4ea6-4594-851e-01282172eabd": {"__data__": {"id_": "f42a8b9f-4ea6-4594-851e-01282172eabd", "embedding": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "dbd66dbf-3521-460c-99da-2efb40e9ce56", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "f16cd5eb95a0ce8c0945c98f03ec3fd1df715ac871611f1c14d68322d2863fdc"}, "2": {"node_id": "a340ca99-39a6-49c9-b799-60c944599307", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "7bd661a8d4d12606c6e9a93da780ecc48130afa142c70b4200021a72e1a1e3d9"}, "3": {"node_id": "6ab2770e-1185-4161-94d2-351be495d3b8", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "ab12d81aa92f4bdc50ffbd8d731706be2b716f173071e30f54a37c369fd57919"}}, "hash": "28c4876593252db78883d165f4dd5282001e2100fdea8c8e9f345c45e496f576", "text": "(L1):\u0015jj^\fjj1=\u0015Pj^\fj\n{ Shrinks coe\u000ecients to zero, and is robust to outliers\nRidge (L2):\u0015jj^\fjj2=\u0015P(^\f)2\n{ Reduces e\u000bects of multicollinearity\nCombining LASSO and Ridge gives Elastic NetLogistic Regression\nPredicts probability that ybelongs to a binary class.\nEstimates\fthrough maximum likelihood estimation (MLE)\nby \ftting a logistic (sigmoid) function to the data. This is\nequivalent to minimizing the cross entropy loss. Regularization\ncan be added in the exponent.\nP(Y= 1) =1\n1 +e\u0000(\f0+\fx)\nThe threshold aclassi\fes predictions as either 1 or 0\nAssumptions\n{ Linear relationship between X and log-odds of Y\n{ Independent observations\n{ Low multicollinearity\nOdds - output probability can be transformed using\nOdds (Y= 1) =P(Y=1)\n1\u0000P(Y=1), whereP(1\n3) = 1:2 odds\nCoe\u000ecients are linearly related to odds, such that a one unit\nincrease in x1a\u000bects odds by e\f1\nDecision Trees\nClassi\fcation and Regression Tree\nCART for regression minimizes SSE by splitting data into\nsub-regions and predicting the average value at leaf nodes.\nThe complexity parameter cponly keeps splits that reduce loss\nby at least cp(smallcp!deep tree)\nCART for classi\fcation minimizes the sum of region impurity,\nwhere ^piis the probability of a sample being in category i.\nPossible measures, each with a max impurity of 0.5.\n{ Gini Impurity = 1 \u0000P( ^pi)2\n{ Cross Entropy = \u0000P( ^pi)log2( ^pi)\nAt each leaf node, CART predicts the most", "start_char_idx": 4440, "end_char_idx": 5843, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6ab2770e-1185-4161-94d2-351be495d3b8": {"__data__": {"id_": "6ab2770e-1185-4161-94d2-351be495d3b8", "embedding": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "dbd66dbf-3521-460c-99da-2efb40e9ce56", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "f16cd5eb95a0ce8c0945c98f03ec3fd1df715ac871611f1c14d68322d2863fdc"}, "2": {"node_id": "f42a8b9f-4ea6-4594-851e-01282172eabd", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "28c4876593252db78883d165f4dd5282001e2100fdea8c8e9f345c45e496f576"}}, "hash": "ab12d81aa92f4bdc50ffbd8d731706be2b716f173071e30f54a37c369fd57919", "text": "^pi)\nAt each leaf node, CART predicts the most frequent category,\nassuming false negative and false positive costs are the same.\nThe splitting process handles multicollinearity and outliers.\nTrees are prone to high variance, so tune through CV.\nRandom Forest\nTrains an ensemble of trees that vote for the \fnal prediction\nBootstrapping - sampling with replacement (will contain\nduplicates), until the sample is as large as the training set\nBagging - training independent models on di\u000berent subsets of\nthe data, which reduces variance. Each tree is trained on\n\u001863% of the data, so the out-of-bag 37% can estimate\nprediction error without resorting to CV.\nDeep trees may over\ft, but adding more trees does not cause\nover\ftting. Model bias is always equal to one of its individual\ntrees.\nVariable Importance - ranks variables by their ability to\nminimize error when split upon, averaged across all trees\nAaron Wang", "start_char_idx": 5819, "end_char_idx": 6729, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "c024f6af-d12e-4682-a843-d3be0eb13816": {"__data__": {"id_": "c024f6af-d12e-4682-a843-d3be0eb13816", "embedding": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "843a0346-cd99-42f5-8a53-c83cee2e5cdd", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "f16cd5eb95a0ce8c0945c98f03ec3fd1df715ac871611f1c14d68322d2863fdc"}, "3": {"node_id": "9c3bd35e-b8d3-461d-8435-d5cd8dadce80", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "4a4247d908dec4d07776a78c4fece09ece6787f60a9a97fe843f71884eb6284b"}}, "hash": "27ff12ae60c00cc65c484ea528ba69ca019660a797f2e5952e25802d7c9370e0", "text": "Data Science Cheatsheet 2.0\nLast Updated June 19, 2021\nDistributions\nDiscrete\nBinomial -xsuccesses in nevents, each with pprobability\n!\u0000n\nx\u0001\npxqn\u0000x, with\u0016=npand\u001b2=npq\n{ If n = 1, this is a Bernoulli distribution\nGeometric - \frst success with pprobability on the nthtrial\n!qn\u00001p, with\u0016= 1=pand\u001b2=1\u0000p\np2\nNegative Binomial - number of failures before rsuccesses\nHypergeometric -xsuccesses in ndraws, no replacement,\nfrom a size Npopulation with Xitems of that feature\n!\u0010X\nx\u0011\u0010N\u0000X\nn\u0000x\u0011\n\u0010N\nn\u0011 , with\u0016=nX\nN\nPoisson - number of successes xin a \fxed time interval, where\nsuccess occurs at an average rate \u0015!\u0015xe\u0000\u0015\nx!, with\u0016=\u001b2=\u0015\nContinuous\nUniform - all values between aandbare equally likely\n!1\nb\u0000awith\u0016=a+b\n2and\u001b2=(b\u0000a)2\n12orn2\u00001\n12if discrete\nNormal/Gaussian N(\u0016;\u001b), Standard Normal Z\u0018N(0;1)\n{ Central Limit Theorem - sample mean of i.i.d. data\napproaches normal distribution\n{ Empirical Rule - 68%, 95%, and 99.7% of values lie within\none, two, and three standard deviations of the mean\n{ Normal Approximation - discrete distributions such as\nBinomial and Poisson can be approximated using z-scores\nwhennp,nq, and\u0015are greater than 10\nExponential - memoryless time between independent events\noccurring at an average rate \u0015!\u0015e\u0000\u0015x, with\u0016=1\n\u0015Gamma - time until nindependent events occurring at an\naverage rate \u0015\nConcepts\nPrediction Error = Bias2+ Variance + Irreducible Noise\nBias - wrong assumptions when training", "start_char_idx": 0, "end_char_idx": 1404, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9c3bd35e-b8d3-461d-8435-d5cd8dadce80": {"__data__": {"id_": "9c3bd35e-b8d3-461d-8435-d5cd8dadce80", "embedding": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "843a0346-cd99-42f5-8a53-c83cee2e5cdd", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "f16cd5eb95a0ce8c0945c98f03ec3fd1df715ac871611f1c14d68322d2863fdc"}, "2": {"node_id": "c024f6af-d12e-4682-a843-d3be0eb13816", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "27ff12ae60c00cc65c484ea528ba69ca019660a797f2e5952e25802d7c9370e0"}, "3": {"node_id": "23b8daa0-1701-4d94-a824-cfcfff5dc03d", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "7bd661a8d4d12606c6e9a93da780ecc48130afa142c70b4200021a72e1a1e3d9"}}, "hash": "4a4247d908dec4d07776a78c4fece09ece6787f60a9a97fe843f71884eb6284b", "text": "Variance + Irreducible Noise\nBias - wrong assumptions when training !can't capture\nunderlying patterns !under\ft\nVariance - sensitive to \ructuations when training !can't\ngeneralize on unseen data !over\ft\nThe bias-variance tradeo\u000b attempts to minimize these two\nsources of error, through methods such as:\n{ Cross validation to generalize to unseen data\n{ Dimension reduction and feature selection\nIn all cases, as variance decreases, bias increases.\nML models can be divided into two types:\n{ Parametric - uses a \fxed number of parameters with\nrespect to sample size\n{ Non-Parametric - uses a \rexible number of parameters and\ndoesn't make particular assumptions on the data\nCross Validation - validates test error with a subset of\ntraining data, and selects parameters to maximize average\nperformance\n{k-fold - divide data into kgroups, and use one to validate\n{ leave-p-out - usepsamples to validate and the rest to trainModel Evaluation\nRegression\nMean Squared Error (MSE) =1\nnP(yi\u0000^y)2\nSum of Squared Error (SSE) =P(yi\u0000^y)2\nTotal Sum of Squares (SST) =P(yi\u0000\u0016y)2\nR2= 1\u0000SSE\nSST, the proportion of explained y-variability\nNote, negative R2means the model is worse than just\npredicting the mean. R2is not valid for nonlinear models, as\nSSresidual+SSerror6=SST.\nAdjusted R2= 1\u0000(1\u0000R2)N\u00001\nN\u0000p\u00001, which changes only when\npredictors a\u000bect R2above what would be expected by chance\nClassi\fcation\nPredict Yes Predict No\nActual Yes True Positive (1\u0000\f) False Negative ( \f)\nActual No False Positive ( \u000b) True Negative (1 \u0000\u000b)\n{ Precision =TP\nTP+FP,", "start_char_idx": 1346, "end_char_idx": 2879, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "23b8daa0-1701-4d94-a824-cfcfff5dc03d": {"__data__": {"id_": "23b8daa0-1701-4d94-a824-cfcfff5dc03d", "embedding": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "843a0346-cd99-42f5-8a53-c83cee2e5cdd", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "f16cd5eb95a0ce8c0945c98f03ec3fd1df715ac871611f1c14d68322d2863fdc"}, "2": {"node_id": "9c3bd35e-b8d3-461d-8435-d5cd8dadce80", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "4a4247d908dec4d07776a78c4fece09ece6787f60a9a97fe843f71884eb6284b"}, "3": {"node_id": "e4ab562f-7bec-4616-885e-5a6664c65f43", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "28c4876593252db78883d165f4dd5282001e2100fdea8c8e9f345c45e496f576"}}, "hash": "7bd661a8d4d12606c6e9a93da780ecc48130afa142c70b4200021a72e1a1e3d9", "text": "True Negative (1 \u0000\u000b)\n{ Precision =TP\nTP+FP, percent correct when predict positive\n{ Recall, Sensitivity =TP\nTP+FN, percent of actual positives\nidenti\fed correctly (True Positive Rate)\n{ Speci\fcity =TN\nTN+FP, percent of actual negatives identi\fed\ncorrectly, also 1 - FPR (True Negative Rate)\n{F1= 2precision\u0001recall\nprecision +recall, useful when classes are imbalanced\nROC Curve - plots TPR vs. FPR for every threshold \u000b. Area\nUnder the Curve measures how likely the model di\u000berentiates\npositives and negatives (perfect AUC = 1, baseline = 0.5).\nPrecision-Recall Curve - focuses on the correct prediction\nof the minority class, useful when data is imbalanced\nLinear Regression\nModels linear relationships between a continuous response and\nexplanatory variables\nOrdinary Least Squares - \fnd ^\ffor ^y=^\f0+^\fX+\u000fby\nsolving ^\f= (XTX)\u00001XTYwhich minimizes the SSE\nAssumptions\n{ Linear relationship and independent observations\n{ Homoscedasticity - error terms have constant variance\n{ Errors are uncorrelated and normally distributed\n{ Low multicollinearity\nVariance In\ration Factor - measures the severity of\nmulticollinearity!1\n1\u0000Ri2, whereRi2is found by regressing\nXiagainst all other variables (a common VIF cuto\u000b is 10)\nRegularization\nAdd a penalty \u0015for large coe\u000ecients to the cost function,\nwhich reduces over\ftting. Requires normalized data.\nSubset (L0):\u0015jj^\fjj0=\u0015(numberof non\u0000zerovariables )\n{ Computationally slow, need to \ft 2kmodels\n{ Alternatives: forward and backward stepwise selection\nLASSO (L1):\u0015jj^\fjj1=\u0015Pj^\fj\n{", "start_char_idx": 2901, "end_char_idx": 4423, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e4ab562f-7bec-4616-885e-5a6664c65f43": {"__data__": {"id_": "e4ab562f-7bec-4616-885e-5a6664c65f43", "embedding": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "843a0346-cd99-42f5-8a53-c83cee2e5cdd", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "f16cd5eb95a0ce8c0945c98f03ec3fd1df715ac871611f1c14d68322d2863fdc"}, "2": {"node_id": "23b8daa0-1701-4d94-a824-cfcfff5dc03d", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "7bd661a8d4d12606c6e9a93da780ecc48130afa142c70b4200021a72e1a1e3d9"}, "3": {"node_id": "6cc7649d-a96c-4ba7-a1a1-336f74375fc8", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "ab12d81aa92f4bdc50ffbd8d731706be2b716f173071e30f54a37c369fd57919"}}, "hash": "28c4876593252db78883d165f4dd5282001e2100fdea8c8e9f345c45e496f576", "text": "(L1):\u0015jj^\fjj1=\u0015Pj^\fj\n{ Shrinks coe\u000ecients to zero, and is robust to outliers\nRidge (L2):\u0015jj^\fjj2=\u0015P(^\f)2\n{ Reduces e\u000bects of multicollinearity\nCombining LASSO and Ridge gives Elastic NetLogistic Regression\nPredicts probability that ybelongs to a binary class.\nEstimates\fthrough maximum likelihood estimation (MLE)\nby \ftting a logistic (sigmoid) function to the data. This is\nequivalent to minimizing the cross entropy loss. Regularization\ncan be added in the exponent.\nP(Y= 1) =1\n1 +e\u0000(\f0+\fx)\nThe threshold aclassi\fes predictions as either 1 or 0\nAssumptions\n{ Linear relationship between X and log-odds of Y\n{ Independent observations\n{ Low multicollinearity\nOdds - output probability can be transformed using\nOdds (Y= 1) =P(Y=1)\n1\u0000P(Y=1), whereP(1\n3) = 1:2 odds\nCoe\u000ecients are linearly related to odds, such that a one unit\nincrease in x1a\u000bects odds by e\f1\nDecision Trees\nClassi\fcation and Regression Tree\nCART for regression minimizes SSE by splitting data into\nsub-regions and predicting the average value at leaf nodes.\nThe complexity parameter cponly keeps splits that reduce loss\nby at least cp(smallcp!deep tree)\nCART for classi\fcation minimizes the sum of region impurity,\nwhere ^piis the probability of a sample being in category i.\nPossible measures, each with a max impurity of 0.5.\n{ Gini Impurity = 1 \u0000P( ^pi)2\n{ Cross Entropy = \u0000P( ^pi)log2( ^pi)\nAt each leaf node, CART predicts the most", "start_char_idx": 4440, "end_char_idx": 5843, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6cc7649d-a96c-4ba7-a1a1-336f74375fc8": {"__data__": {"id_": "6cc7649d-a96c-4ba7-a1a1-336f74375fc8", "embedding": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "843a0346-cd99-42f5-8a53-c83cee2e5cdd", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "f16cd5eb95a0ce8c0945c98f03ec3fd1df715ac871611f1c14d68322d2863fdc"}, "2": {"node_id": "e4ab562f-7bec-4616-885e-5a6664c65f43", "node_type": null, "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}, "hash": "28c4876593252db78883d165f4dd5282001e2100fdea8c8e9f345c45e496f576"}}, "hash": "ab12d81aa92f4bdc50ffbd8d731706be2b716f173071e30f54a37c369fd57919", "text": "^pi)\nAt each leaf node, CART predicts the most frequent category,\nassuming false negative and false positive costs are the same.\nThe splitting process handles multicollinearity and outliers.\nTrees are prone to high variance, so tune through CV.\nRandom Forest\nTrains an ensemble of trees that vote for the \fnal prediction\nBootstrapping - sampling with replacement (will contain\nduplicates), until the sample is as large as the training set\nBagging - training independent models on di\u000berent subsets of\nthe data, which reduces variance. Each tree is trained on\n\u001863% of the data, so the out-of-bag 37% can estimate\nprediction error without resorting to CV.\nDeep trees may over\ft, but adding more trees does not cause\nover\ftting. Model bias is always equal to one of its individual\ntrees.\nVariable Importance - ranks variables by their ability to\nminimize error when split upon, averaged across all trees\nAaron Wang", "start_char_idx": 5819, "end_char_idx": 6729, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a2860dd2-d182-4ff0-abfd-6c456a90183c": {"__data__": {"id_": "a2860dd2-d182-4ff0-abfd-6c456a90183c", "embedding": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "Almanack.pdf", "node_type": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902"}}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "text": "THE ALMANACK OF NAVAL RAVIKANT", "start_char_idx": 0, "end_char_idx": 30, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d6c9e43e-7cbf-4d12-b4d0-3831c763ab4e": {"__data__": {"id_": "d6c9e43e-7cbf-4d12-b4d0-3831c763ab4e", "embedding": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "Almanack.pdf", "node_type": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902"}}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "text": "THE ALMANACK OF NAVAL RAVIKANT", "start_char_idx": 0, "end_char_idx": 30, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d4f10034-90e8-4fdc-9448-64d4637cfa69": {"__data__": {"id_": "d4f10034-90e8-4fdc-9448-64d4637cfa69", "embedding": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "Almanack.pdf", "node_type": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902"}}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "text": "THE ALMANACK OF NAVAL RAVIKANT", "start_char_idx": 0, "end_char_idx": 30, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ca3af7a1-356c-4696-bc8a-6e11c2853eac": {"__data__": {"id_": "ca3af7a1-356c-4696-bc8a-6e11c2853eac", "embedding": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "Almanack.pdf", "node_type": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902"}}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "text": "THE ALMANACK OF NAVAL RAVIKANT", "start_char_idx": 0, "end_char_idx": 30, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "62d34951-bd9b-4d86-8790-f0048047f935": {"__data__": {"id_": "62d34951-bd9b-4d86-8790-f0048047f935", "embedding": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "Almanack.pdf", "node_type": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902"}}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "text": "THE ALMANACK OF NAVAL RAVIKANT", "start_char_idx": 0, "end_char_idx": 30, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "2f211657-9e5f-48d7-93af-858c1952cdf8": {"__data__": {"id_": "2f211657-9e5f-48d7-93af-858c1952cdf8", "embedding": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "Almanack.pdf", "node_type": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902"}}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "text": "THE ALMANACK OF NAVAL RAVIKANT", "start_char_idx": 0, "end_char_idx": 30, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "17df73c0-8660-4d8e-a6e2-bf2bbfd6fe67": {"__data__": {"id_": "17df73c0-8660-4d8e-a6e2-bf2bbfd6fe67", "embedding": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "Almanack.pdf", "node_type": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902"}}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "text": "THE ALMANACK OF NAVAL RAVIKANT", "start_char_idx": 0, "end_char_idx": 30, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "82ab5f51-7805-4e32-8d00-962096d264aa": {"__data__": {"id_": "82ab5f51-7805-4e32-8d00-962096d264aa", "embedding": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "Almanack.pdf", "node_type": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902"}}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "text": "THE ALMANACK OF NAVAL RAVIKANT", "start_char_idx": 0, "end_char_idx": 30, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a0765b7f-f84a-4367-98a9-58723be9d283": {"__data__": {"id_": "a0765b7f-f84a-4367-98a9-58723be9d283", "embedding": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "Almanack.pdf", "node_type": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902"}}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "text": "THE ALMANACK OF NAVAL RAVIKANT", "start_char_idx": 0, "end_char_idx": 30, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1108e9b5-b5ca-45f8-bead-d2804fdd2f92": {"__data__": {"id_": "1108e9b5-b5ca-45f8-bead-d2804fdd2f92", "embedding": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "Almanack.pdf", "node_type": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902"}}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "text": "THE ALMANACK OF NAVAL RAVIKANT", "start_char_idx": 0, "end_char_idx": 30, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "44806d3c-d841-4ab4-8612-744b851b0d42": {"__data__": {"id_": "44806d3c-d841-4ab4-8612-744b851b0d42", "embedding": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "Almanack.pdf", "node_type": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902"}}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "text": "THE ALMANACK OF NAVAL RAVIKANT", "start_char_idx": 0, "end_char_idx": 30, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "34a05564-3a2d-4a68-8255-0b93c121f6ce": {"__data__": {"id_": "34a05564-3a2d-4a68-8255-0b93c121f6ce", "embedding": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "Almanack.pdf", "node_type": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902"}}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "text": "THE ALMANACK OF NAVAL RAVIKANT", "start_char_idx": 0, "end_char_idx": 30, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "3bbcf55e-a5a2-406a-a731-5e120ddebc8e": {"__data__": {"id_": "3bbcf55e-a5a2-406a-a731-5e120ddebc8e", "embedding": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "Almanack.pdf", "node_type": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902"}}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "text": "THE ALMANACK OF NAVAL RAVIKANT", "start_char_idx": 0, "end_char_idx": 30, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6c693848-c017-4995-b1a3-c81978ad21db": {"__data__": {"id_": "6c693848-c017-4995-b1a3-c81978ad21db", "embedding": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "Almanack.pdf", "node_type": null, "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902"}}, "hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "text": "THE ALMANACK OF NAVAL RAVIKANT", "start_char_idx": 0, "end_char_idx": 30, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}}, "docstore/ref_doc_info": {"9b2ad5f8-ab26-4090-beb1-7a5a3d6a42d2": {"node_ids": ["1305a915-b97f-432a-923a-a192add7ebe0", "d7520b64-4628-4d44-9cd5-46e1d8d81a64"], "metadata": {"page_label": "1", "file_name": "understaing-support-vector-machine-example-code.pdf"}}, "dbd66dbf-3521-460c-99da-2efb40e9ce56": {"node_ids": ["3b36b885-cb52-464a-bf34-05771835590b", "2da087bc-0e21-4e03-a6ea-8cc88d49dbd5", "a340ca99-39a6-49c9-b799-60c944599307", "f42a8b9f-4ea6-4594-851e-01282172eabd", "6ab2770e-1185-4161-94d2-351be495d3b8"], "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}}, "843a0346-cd99-42f5-8a53-c83cee2e5cdd": {"node_ids": ["c024f6af-d12e-4682-a843-d3be0eb13816", "9c3bd35e-b8d3-461d-8435-d5cd8dadce80", "23b8daa0-1701-4d94-a824-cfcfff5dc03d", "e4ab562f-7bec-4616-885e-5a6664c65f43", "6cc7649d-a96c-4ba7-a1a1-336f74375fc8"], "metadata": {"page_label": "1", "file_name": "Data_Science_Cheatsheet.pdf"}}, "Almanack.pdf": {"node_ids": ["a2860dd2-d182-4ff0-abfd-6c456a90183c", "d6c9e43e-7cbf-4d12-b4d0-3831c763ab4e", "d4f10034-90e8-4fdc-9448-64d4637cfa69", "ca3af7a1-356c-4696-bc8a-6e11c2853eac", "62d34951-bd9b-4d86-8790-f0048047f935", "2f211657-9e5f-48d7-93af-858c1952cdf8", "17df73c0-8660-4d8e-a6e2-bf2bbfd6fe67", "82ab5f51-7805-4e32-8d00-962096d264aa", "a0765b7f-f84a-4367-98a9-58723be9d283", "1108e9b5-b5ca-45f8-bead-d2804fdd2f92", "44806d3c-d841-4ab4-8612-744b851b0d42", "34a05564-3a2d-4a68-8255-0b93c121f6ce", "3bbcf55e-a5a2-406a-a731-5e120ddebc8e", "6c693848-c017-4995-b1a3-c81978ad21db"], "metadata": {"page_label": "1", "file_name": "Almanack.pdf"}}}, "docstore/metadata": {"1305a915-b97f-432a-923a-a192add7ebe0": {"doc_hash": "57ece9fbdebcda7b56e1fe9c2c7fe57038f5b4c97228f3692fe207541382a2b4", "ref_doc_id": "9b2ad5f8-ab26-4090-beb1-7a5a3d6a42d2"}, "d7520b64-4628-4d44-9cd5-46e1d8d81a64": {"doc_hash": "1e27def494d9833a3cf428648305b4e91c532b0272c032e63034b202a5175e8f", "ref_doc_id": "9b2ad5f8-ab26-4090-beb1-7a5a3d6a42d2"}, "9b2ad5f8-ab26-4090-beb1-7a5a3d6a42d2": {"doc_hash": "4ea16c65a00d52976b68fa9789a367f51d7f21e36fd6befb49e3c539b4a95107"}, "3b36b885-cb52-464a-bf34-05771835590b": {"doc_hash": "27ff12ae60c00cc65c484ea528ba69ca019660a797f2e5952e25802d7c9370e0", "ref_doc_id": "dbd66dbf-3521-460c-99da-2efb40e9ce56"}, "2da087bc-0e21-4e03-a6ea-8cc88d49dbd5": {"doc_hash": "4a4247d908dec4d07776a78c4fece09ece6787f60a9a97fe843f71884eb6284b", "ref_doc_id": "dbd66dbf-3521-460c-99da-2efb40e9ce56"}, "a340ca99-39a6-49c9-b799-60c944599307": {"doc_hash": "7bd661a8d4d12606c6e9a93da780ecc48130afa142c70b4200021a72e1a1e3d9", "ref_doc_id": "dbd66dbf-3521-460c-99da-2efb40e9ce56"}, "f42a8b9f-4ea6-4594-851e-01282172eabd": {"doc_hash": "28c4876593252db78883d165f4dd5282001e2100fdea8c8e9f345c45e496f576", "ref_doc_id": "dbd66dbf-3521-460c-99da-2efb40e9ce56"}, "6ab2770e-1185-4161-94d2-351be495d3b8": {"doc_hash": "ab12d81aa92f4bdc50ffbd8d731706be2b716f173071e30f54a37c369fd57919", "ref_doc_id": "dbd66dbf-3521-460c-99da-2efb40e9ce56"}, "dbd66dbf-3521-460c-99da-2efb40e9ce56": {"doc_hash": "f16cd5eb95a0ce8c0945c98f03ec3fd1df715ac871611f1c14d68322d2863fdc"}, "c024f6af-d12e-4682-a843-d3be0eb13816": {"doc_hash": "27ff12ae60c00cc65c484ea528ba69ca019660a797f2e5952e25802d7c9370e0", "ref_doc_id": "843a0346-cd99-42f5-8a53-c83cee2e5cdd"}, "9c3bd35e-b8d3-461d-8435-d5cd8dadce80": {"doc_hash": "4a4247d908dec4d07776a78c4fece09ece6787f60a9a97fe843f71884eb6284b", "ref_doc_id": "843a0346-cd99-42f5-8a53-c83cee2e5cdd"}, "23b8daa0-1701-4d94-a824-cfcfff5dc03d": {"doc_hash": "7bd661a8d4d12606c6e9a93da780ecc48130afa142c70b4200021a72e1a1e3d9", "ref_doc_id": "843a0346-cd99-42f5-8a53-c83cee2e5cdd"}, "e4ab562f-7bec-4616-885e-5a6664c65f43": {"doc_hash": "28c4876593252db78883d165f4dd5282001e2100fdea8c8e9f345c45e496f576", "ref_doc_id": "843a0346-cd99-42f5-8a53-c83cee2e5cdd"}, "6cc7649d-a96c-4ba7-a1a1-336f74375fc8": {"doc_hash": "ab12d81aa92f4bdc50ffbd8d731706be2b716f173071e30f54a37c369fd57919", "ref_doc_id": "843a0346-cd99-42f5-8a53-c83cee2e5cdd"}, "843a0346-cd99-42f5-8a53-c83cee2e5cdd": {"doc_hash": "f16cd5eb95a0ce8c0945c98f03ec3fd1df715ac871611f1c14d68322d2863fdc"}, "a2860dd2-d182-4ff0-abfd-6c456a90183c": {"doc_hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "ref_doc_id": "Almanack.pdf"}, "Almanack.pdf": {"doc_hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902"}, "d6c9e43e-7cbf-4d12-b4d0-3831c763ab4e": {"doc_hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "ref_doc_id": "Almanack.pdf"}, "d4f10034-90e8-4fdc-9448-64d4637cfa69": {"doc_hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "ref_doc_id": "Almanack.pdf"}, "ca3af7a1-356c-4696-bc8a-6e11c2853eac": {"doc_hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "ref_doc_id": "Almanack.pdf"}, "62d34951-bd9b-4d86-8790-f0048047f935": {"doc_hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "ref_doc_id": "Almanack.pdf"}, "2f211657-9e5f-48d7-93af-858c1952cdf8": {"doc_hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "ref_doc_id": "Almanack.pdf"}, "17df73c0-8660-4d8e-a6e2-bf2bbfd6fe67": {"doc_hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "ref_doc_id": "Almanack.pdf"}, "82ab5f51-7805-4e32-8d00-962096d264aa": {"doc_hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "ref_doc_id": "Almanack.pdf"}, "a0765b7f-f84a-4367-98a9-58723be9d283": {"doc_hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "ref_doc_id": "Almanack.pdf"}, "1108e9b5-b5ca-45f8-bead-d2804fdd2f92": {"doc_hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "ref_doc_id": "Almanack.pdf"}, "44806d3c-d841-4ab4-8612-744b851b0d42": {"doc_hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "ref_doc_id": "Almanack.pdf"}, "34a05564-3a2d-4a68-8255-0b93c121f6ce": {"doc_hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "ref_doc_id": "Almanack.pdf"}, "3bbcf55e-a5a2-406a-a731-5e120ddebc8e": {"doc_hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "ref_doc_id": "Almanack.pdf"}, "6c693848-c017-4995-b1a3-c81978ad21db": {"doc_hash": "60ae51d621b3a291f3685b6fa16ae15e4033ebc06005b6dd6778ebeae964c902", "ref_doc_id": "Almanack.pdf"}}}